---
title: "Course notes: Simulation-based Inference for Epidemiological Dynamics (Aaron A. King)"
date: 2023-05-25
permalink: /posts/2023-05-25/pomp-notes
categories:
  - Course notes
tags:
  - Infectious Disease Modelling
toc: true
last_modified_at: 2023-07-28
---

This post records the notes when I learnt the [Simulation-based Inference for Epidemiological Dynamics](https://kingaa.github.io/sbied/) by Aaron A. King, Edward L. Ionides, Jesse Wheeler. 

I learn this for better understanding of the details of IDM, and more practically, how to implement IDM using a Bayesian framework using R.

> A world is just a single realization of a stochastic process.

Some useful links here:
- [ ] [Simulation-based Inference for Epidemiological Dynamics](https://kingaa.github.io/sbied/)
- [ ] [Model-based Inference in Ecology and Epidemiology](https://kingaa.github.io/short-course/)
- [ ] [Implementing a POMP model from scratch](https://kingaa.github.io/sbied/intro/ricker.html)
- [ ] [Getting started with pomp](https://kingaa.github.io/pomp/vignettes/getting_started.html)
- [ ] [pomp: statistical inference for partially-observed Markov processes](https://kingaa.github.io/pomp/docs.html)
- [ ] [Two views of the pomp project](https://www.youtube.com/playlist?list=PLluGwj6FGt2SufYmENYAngy8dEMtfFEU8)
- [ ] [Partially observed Markov processes with spatial structure via the R package spatPomp](https://arxiv.org/abs/2101.01157)


---

## 0: [Installing POMP](https://kingaa.github.io/sbied/prep/index.html)

## 1: [Introduction to Simulation-based Inference for Epidemiological Dynamics](https://kingaa.github.io/sbied/intro/index.html)
### What makes epidemiological inference hard? 
#### Epidemiological and Ecological Dynamics
Ecological systems are complex, open, nonlinear and nonstationary. It is useful to model them as stochastic models. For any observable phenomenon, multiple competing explanations are possible. Time series are particularly useful sources of data.
#### Obstacles to inference
Obstacles for ecological modeling and inference via nonlinear mechanistic models enumerated by Bjørnstad and Grenfell (2001)
1. Combining measurement noise and process noise.
2. Including covariates in mechanistically plausible ways.
3. Using continuous-time models.
4. Modeling and estimating interactions in coupled systems. 
5. Dealing with unobserved variables.
6. Modeling spatial-temporal dynamics.

#### Others
- How does one use incidence and mobility data to infer key epidemiological parameters? ([Andrade and Duggan, 2022](https://doi.org/10.1371/journal.pcbi.1010206))

### Partially observed Markov processes model
Also called hidden Markov model or state space model.
#### Mathematical definition
- Data $y^{\ast}_1,...,y^{\ast}_N$ collected at times $t_1<...<t_N$ are modeled as noisy, incomplete, and indirect *observations of a Markov process* $\{X(t), t ≥ t_0\}$.
- $\{X(t)\}$ is Markov if the history of the process, $\{X(s), s ≤ t\}$, is uninformative about the future of the process, $\{X(s), s ≥ t\}$, given the current value of the process, $X(t)$.
- In other words, Markov property holds if everything important for the dynamics of the system at $X_t$, we don't need to remember anything in the history to talk about the future process. 
- An **important** special case: any system of differential equations $dx/dt = f(x)$ is Markovian.

> A model is a data generating process: data are the realization of some stochastic process, and a model is to describe the stochastic process. 

#### Notation for POMP models
- Write $X_n = X(t_n)$ and $X_{0:N} = (X_0, ... , X_N)$. Let $Y_n$ be a random variable modeling the observation at time $t_n$.
- The one-step transition density, $f_{X_n \vert X_{n−1}}(x_n\vert x_{n−1};θ)$, together with the measurement density, $f_{Y_n \vert X_n} (y_n \vert x_n; θ)$ and the initial density, $f_{X_0} (x_0; θ)$, specify the entire POMP model.
- The joint density $f_{X_{0:N} ,Y_{1:N}} (x_{0:N}, y_{1:N}; θ)$ can be written as $$ f_{X_0}(x_0;θ) \prod_{n=1}^{N} f_{X_n \vert X_{n−1}}(x_n \vert x_{n−1};θ)f_{Y_n \vert X_n}(y_n \vert x_n;θ)$$

- The marginal density for $Y_{1:N}$ evaluated at the data, $y^∗_{1:N}$, is
$$f_{Y_{1:N}}(y_{1:N}^* \vert \theta)= \int f_{X_{0:N} ,Y_{1:N}} (x_{0:N}, y_{1:N}^*; θ) dx_{0:N}$$

#### POMP model schematic

  <img src="/files/2023-05-25-pomp/Screenshot%202023-05-27%20at%205.41.40%20PM.webp" width="500"/>
  
- The state process, $X_n$, is Markovian, i.e.,
$f_{X_n \vert X_{0:n−1} ,Y_{1:n−1}} (x_n \vert x_{0:n−1} , y_{1:n−1}) = f_{X_n \vert X_{n−1}} (x_n  \vert x_{n−1})$.
- Moreover, $Y_n$, depends only on the state at that time: $f_{Y_n \vert X_{0:N},Y_{1:n−1}}(y_n \vert x_{0:n},y_{1:n−1}) = f_{Y_n \vert X_n}(y_n \vert x_n)$, for $n = 1,...,N$.

#### What is a simulation-based method?
- Simulating random processes is often much easier than evaluating their transition probabilities.
- In other words, we may be able to write rprocess but not dprocess.
- **Simulation-based** methods require the user to specify rprocess but not dprocess.
- **Plug-and-play**, **likelihood-free** and **equation-free** are alternative terms for “simulation-based” methods.
- Much development of simulation-based statistical methodology has occurred in the past decade.

### The pomp package
It is useful to divide the pomp package functionality into different levels:
- *Basic model components*
  - `rinit`: simulator for the initial-state distribution, i.e., the distribution of the latent state at time $t_0$.
  - `rprocess` and `dprocess`: simulator and density evaluation procedure, respectively, for the process model.
  - `rmeasure` and `dmeasure`: simulator and density evaluation procedure, respectively, for the measurement model.
  - `rprior` and `dprior`: simulator and density evaluation procedure, respectively, for the prior distribution.
  - `skeleton`: evaluation of a deterministic skeleton.
  - `partrans`: parameter transformations.
- *Workhorses*
  
  Workhorses are R functions, built into the package, that cause the basic model component procedures to be executed.
- *Elementary POMP algorithms*
  
  These are algorithms that interrogate the model or the model/data confrontation without attempting to estimate parameters. There are currently four of these:
  - `simulate` performs simulations of the POMP model, i.e., it samples from the joint distribution of latent states and observables.
  - `pfilter` runs a sequential Monte Carlo (particle filter) algorithm to compute the likelihood and (optionally) estimate the prediction and filtering distributions of the latent state process.
  - `probe` computes one or more uni or multivariate summary statistics on both actual and simulated data.
  - `spect` estimates the power spectral density functions for the actual and simulated data.
- *Inference algorithms*
  - `abc`: approximate Bayesian computation
  - `bsmc2`: Liu-West algorithm for Bayesian SMC
  - `pmcmc`: a particle MCMC algorithm
  - `mif2`: iterated filtering (IF2)
  - `enkf`, eakf ensemble and ensemble adjusted Kalman filters 
  - `traj` objfun: trajectory matching
  - `spect` objfun: power spectrum matching
  - `probe` objfun: probe matching
  - `nlf` objfun: nonlinear forecasting

## 2: [Simulation of stochastic dynamic models](https://kingaa.github.io/sbied/stochsim/index.html)

### Compartment models
- A basic SIR model:

  <img src="/files/2023-05-25-pomp/Screenshot%202023-05-28%20at%204.19.02%20PM.webp" width="500"/>

- A deterministic interpretation:
$$
\frac{dN_{SI}}{dt} = \mu_{SI}(t)S(t)\\
\frac{dN_{IR}}{dt} = \mu_{IR}I(t)
$$
- A stochastic interpretation:
$$
\mathbb{P}(N_{SI}(t+\delta)=N_{SI}(t)+1)=\mu_{SI}(t)S(t)\delta+o(\delta)\\
\mathbb{P}(N_{SI}(t+\delta)=N_{SI}(t))=1-\mu_{SI}(t)S(t)\delta+o(\delta)\\
\mathbb{P}(N_{IR}(t+\delta)=N_{IR}(t)+1)=\mu_{IR}I(t)\delta+o(\delta)\\
\mathbb{P}(N_{IR}(t+\delta)=N_{IR}(t))=1-\mu_{IR}I(t)\delta+o(\delta)
$$

### Euler’s method
#### Numerical solution of deterministic dynamics
- Euler’s method for ordinary differential equations
Mathematical analysis of Euler’s method says that, as long as the function $h(x)$ is not too exotic, then $x(t)$ is well approximated by $\tilde{x}(t)$ when the discretization time-step, δ, is sufficiently small.
- Numerical solution of stochastic dynamics:
  1. A Poisson approximation:$$\tilde{N}_{SI}(t+\delta) = \tilde{N}_{SI} + Poisson[\mu_{SI}(\tilde{I}(t))\tilde{S}(t)\delta] $$
  2. A binomial approximation:$$\tilde{N}_{SI}(t+\delta) = \tilde{N}_{SI} + Binomial[\tilde{S}(t), \mu_{SI}(\tilde{I}(t))\delta] $$
  3. A binomial approximation with exponential transition probabilities:$$\tilde{N}_{SI}(t+\delta) = \tilde{N}_{SI} + Binomial[\tilde{S}(t), 1-exp\{-\mu_{SI}(\tilde{I}(t))\delta\}] $$
  - Analytically, it is usually easiest to reason using (1) or (2). Practically, it is usually preferable to work
  with (3).
  - Numerically, Gillespie’s algorithm is often approximated using so-called tau-leaping methods. These are closely related to Euler’s approach. In this context, the Euler method has sometimes been called tau-leaping.
  - For constant-rate compartmental models, the Gillespie algorithm gives an exact solution at the expense of additional computation time. We may on occastion want an exact simulator, and in that case Gillespie can be used.

### Compartment models in pomp
- There is a term called *accumulator variable* in pomp, specified by `accumvars` , which will be reset to zero at the beginning of each observation.
- *C snippets* are preferred.

## 3: [Likelihood for POMPs: theory and practice](https://kingaa.github.io/sbied/pfilter/index.html)

### Introduction
The following schematic diagram represents conceptual links between different components of the methodological approach we’re developing for statistical inference on epidemiological dynamics.

<img src="/files/2023-05-25-pomp/Screenshot%202023-05-28%20at%2011.02.05%20PM.webp" width="500"/>

In this lesson, we’re going to discuss the orange compartments.
The Monte Carlo technique called the “particle filter” is central for connecting the higher-level ideas of POMP models and likelihood-based inference to the lower-level tasks involved in carrying out data analysis.
### The likelihood function
#### Definition of the likelihood function
$$
\mathcal{L}(\theta)=f_{Y_{1:N}}(y_{1:N}^{*};\theta)
$$
$f_{Y_{1:N}}(y_{1:N};\theta)$ is a probability density function which defines a probability distribution for each value of a parameter vector $\theta$, and $y_{1:N}^{*}$ is the observation, which should be a random draw from the density function.

#### A simulator is implicitly a statistical model
- For simple statistical models, we may describe the model by explicitly writing the density function $f_{Y_{1:N}}(y_{1:N};\theta)$. One may then ask how to simulate a random variable $Y_{1:N} \sim f_{Y_{1:N}}(y_{1:N};\theta)$.
- For many dynamic models it is much more convenient to define the model via a procedure to simulate the random variable $Y_{1:N}$ . This implicitly defines the corresponding density $f_{Y_{1:N}}(y_{1:N};\theta)$.
#### Likelihood of a POMP model
- The marginal density for sequence of measurements, $Y_{1:N}$ , evaluated at the data, $y_{1:N}^*$, is
$$
\begin{align}
\mathcal{L}(\theta) &= f_{Y_{1:N}}(y_{1:N}^*;\theta)\\ &= \int{f_{X_{0:N}, Y_{1:N}}(x_{0:N}, y_{1:N}^*;\theta)}dx_{0:N}\\ &= \int{f_{X_0}(x_0;θ) \prod_{n=1}^{N} f_{X_n \vert X_{n−1}}(x_n \vert x_{n−1};θ)f_{Y_n \vert X_n}(y_n^* \vert x_n;θ)}dx_{0:N},
\end{align}
$$
which can be written as an expectation,
$$
\mathcal{L}(\theta) = \mathbb{E}[\prod_{n=1}^{N}f_{Y_n \vert X_n}(y_n^* \vert x_n;θ)] ,
$$
where the expectation is taken with $X_{0:N}$.
- This integral is high dimensional and, except for the simplest cases, can not be reduced analytically.

### Sequential Monte Carlo: The particle filter
- Particle filter is a much more efficient algorithm than direct Monte Carlo integration.
- Importance sampling can potentially reduce the variance of the Monte Carlo distribution. Illustration please refer to [this video](https://www.youtube.com/watch?v=C3p2wI4RAi8&t=540s).
- A simple video explaining [particle filter](https://www.youtube.com/watch?v=YBeVDxTHiYM).
- Essentially, the particle filter weights the prediction particles $X^P_{n,j}$ by the observation data $y^*_n$, then *resample* the distribution to obtain a filtering distribution.

<img src="/files/2023-05-25-pomp/Screenshot%202023-06-01%20at%2019.25.37.webp" width="600"/>
<img src="/files/2023-05-25-pomp/Screenshot%202023-06-01%20at%2019.25.03.webp" width="600"/>

- Particle filter in pomp:
  ```r
  foreach (i=1:10, .combine=c) %dopar% { 
    library(pomp)
    measSIR %>% pfilter(Np=5000)
  } -> pf
  logLik(pf) -> ll 
  logmeanexp(ll,se=TRUE)
                      se
  -131.934662    0.684017
  ```

### Likelihood-based inference
#### Parameter estimates and uncertainty quantification

There are three main approaches to estimating the statistical uncertainty in an MLE. 
1. The Fisher information.
   - A computationally quick approach when one has access to satisfactory numerical second derivatives of the log likelihood.
   - The approximation is satisfactory only when θˆ is well approximated by a normal distribution.
   - Neither of the two requirements above are typically met for POMP models.
2. Profile likelihood estimation.
   Profile log likelihood function is used in pomp.
3. A simulation study, also known as a bootstrap.
   - If done carefully and well, this can be the best approach.
   - A confidence interval is a claim about reproducibility. You claim, so far as your model is correct, that on 95% of realizations from the model, a 95% confidence interval you have constructed will cover the true value of the parameter.
   - A simulation study can check this claim fairly directly, but requires the most effort.

### Geometry of the likelihood function
We can use slices to study the log likelihood surface.

### More on likelihood-based inference
#### Maximizing the likelihood
- likelihood maximization might be to stick the particle filter log likelihood estimate into a standard numerical optimizer, such as the Nelder-Mead algorithm. But this approach is unsatisfactory. Standard numerical optimizers are not designed to maximize noisy and computationally expensive Monte Carlo functions.
- We’ll present an *iterated filtering algorithm* for maximizing the likelihood in a way that takes advantage of the structure of POMP models and the particle filter.
- Likelihood-based model selection and model diagnostics
  - For nested hypotheses, we can carry out model selection by likelihood ratio tests.
  - For non-nested hypotheses, likelihoods can be compared using Akaike’s information criterion (AIC) or related methods.

#### Likelihood ratio test 
- **Wilks approximation**:
  
  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-01%20at%2019.58.07.webp" width="600"/>
  
- The *Wilks approximation* can be used to construct a hypothesis test of the null hypothesis $H^{⟨0⟩}$ against the alternative $H^{⟨1⟩}$.
- This is called a **likelihood ratio test** since a difference of log likelihoods corresponds to a ratio of likelihoods.
- The chi-squared approximation to the likelihood ratio statistic may be useful, and can be assessed empirically by a simulation study, even in situations that do not formally satisfy any known theorem.
- Wilks’ theorem and profile likelihood:
  
  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-01%20at%2019.58.35.webp" width="600"/>
  

#### Information criteria 
- Akaike’s information criterion (**AIC**) is given by
$AIC = −2 \mathbb{l} (\hat{θ}) + 2 D$, “Minus twice the maximized log likelihood plus twice the number of parameters.”
- AIC was derived as an approach to minimizing prediction error. Increasing the number of parameters leads to additional **overfitting** which can decrease predictive skill of the fitted model.
- AIC does not penalize model complexity beyond the consequence of reduced predictive skill due to overfitting. One can penalize complexity by incorporating a more severe penalty than the 2D term above, such as via [BIC](https://en.wikipedia.org/wiki/Bayesian_information_criterion).

## [4: Iterated filtering: principles and practice](https://kingaa.github.io/sbied/mif/index.html)

### Classification of statistical methods for POMP models
#### The plug-and-play (Simulation-based) methods
- Inference methodology that calls `rprocess` but not `dprocess` is said to be plug-and-play. All popular modern Monte Carlo methods fall into this category.
- Plug-and-play methods can call `dmeasure`. A method that uses only rprocess and rmeasure is called “doubly plug-and-play”.
- Two non-plug-and-play methods, expectation-maximization (**EM**) and Markov chain Monte Carlo (**MCMC**), have theoretical convergence problems for nonlinear POMP models. The failures of these two workhorses of statistical computation have prompted development of alternative methodologies.

#### Full information vs. feature-based methods
- Full-information methods are defined to be those based on the likelihood function for the full data (i.e., likelihood-based frequentist inference and Bayesian inference).
- Feature-based methods either consider a summary statistic (a function of the data) or work with an an alternative to the likelihood.
- Asymptotically, full-information methods are statistically efficient and feature-based methods are not.
- In some cases, loss of statistical efficiency might be an acceptable tradeoff for advantages in computational efficiency.
#### Bayesian vs. frequentist approaches
- Recently, plug-and-play Bayesian methods have been discovered:
  - particle Markov chain Monte Carlo (PMCMC) (Andrieu et al., 2010).
  - approximate Bayesian computation (ABC) (Toni et al., 2009).
- Prior belief specification is both the strength and weakness of Bayesian methodology:
  - The likelihood surface for nonlinear POMP models often contains nonlinear ridges and variations in curvature.
  - These situations bring into question the appropriateness of independent priors derived from expert opinion on marginal distributions of parameters.
  - They also are problematic for specification of “flat” or “uninformative” prior beliefs.
  - Expert opinion can be treated as data for non-Bayesian analysis. However, our primary task is to identify the information in the data under investigation, so it can be helpful to use methods that do not force us to make our conclusions dependent on quantification of prior beliefs.

#### Summary
  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-02%20at%2016.35.06.webp" width="600"/>

### Iterated filtering in theory
#### Full-information, plug-and-play, frequentist methods
- Iteratedfilteringmethods(Ionidesetal.,2006,2015)aretheonlycurrentlyavailable,full-information, plug-and-play, frequentist methods for POMP models.
- Iterated filtering methods have been shown to solve likelihood-based inference problems for epidemiological situations which are computationally intractable for available Bayesian methodology (Ionides et al., 2015).

#### An iterated filtering algorithm (IF2)
We focus on the IF2 algorithm of Ionides et al. (2015). In this algorithm:
- Each iteration consists of a particle filter, carried out with the parameter vector, for each particle, doing a random walk (note the $\Theta^{m}\sim\Theta^{m-1}$ in the below slide).
- At the end of the time series, the collection of parameter vectors is recycled as starting parameters for the next iteration.
- The random-walk variance decreases at each iteration.
In theory, this procedure converges toward the region of parameter space maximizing the maximum likelihood. In practice, we can test this claim on examples.

  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-02%20at%2017.30.47.webp" width="600"/>
  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-02%20at%2017.30.57.webp" width="600"/>
  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-02%20at%2017.31.07.webp" width="600"/>
  <img src="/files/2023-05-25-pomp/Screenshot%202023-06-02%20at%2017.31.20.webp" width="600"/>

### Iterated filtering in practice
There are many codes in practice in this section. Some key information are listed below.
#### Local MLE
- we can first explore a point likelihood by particle filter with a initial parameter vector.
- We could then do a local search of the likelihood surface around this point. We will use `milf2` in this step to maximize the local likelihood. The likelihood from this step is not good enough for reliable inference, because:
  - Partly, this is because parameter perturbations are applied in the last filtering iteration, so that the likelihood reported by mif2 is not identical to that of the model of interest.
  - Partly, this is because mif2 is usually carried out with fewer particles than are needed for a good likelihood evaluation.
- Therefore, we need to evaluate the likelihood, together with a standard error, using replicated particle filters at each point estimate.

#### Global MLE
- To perform a global maximum likelihood estimation:
  - Practical parameter estimation involves trying many starting values for the parameters.
  - One way to approach this is to choose a large box in parameter space that contains all remotely
  sensible parameter vectors.
  - If an estimation method gives stable conclusions with starting values drawn randomly from this box, this gives some confidence that an adequate global search has been carried out.
- We could start with a box of starting parameter vectors, and carry out likelihood maximizations from diverse starting points.

#### Profile likelihood
- From the global MLE results, we could get a “poor man’s profiles”.
- To perform formal profile likelihood, we’ll first bound the uncertainty by putting a box around the highest-likelihood esti- mates we’ve found so far.
- Within this box, we’ll choose some random starting points, for each of several values of $\eta$, which is the parameter we focuses on.
- Now, we’ll start one independent sequence of iterated filtering operations from each of these points. 
- We’ll be careful to keep $\eta$ fixed.
- This is accomplished by not giving this parameter a random perturbation in the `mif2` call.
- 95%CI of $\eta$ can be obtained through this procedure.
- As one varies $\eta$ across the profile, the model compensates by adjusting the other parameters. 
- It can be very instructive to understand how the model does this.
- For example, how does the reporting efficiency, $\rho$, change as $\eta$ is varied?
- We can plot ρ vs $\eta$ across the profile.
- This is called a profile trace.

#### The investigation continues
- If we found that some of the parameter estimation is in conflict of some existing knowledge, we may need to adjust the model, e.g. relax some parameters and fixed some others.
- In iterated filtering, We could adopt a *simulated tempering approach* (following a metallurgical analogy), in which we increase the size of the random perturbations some amount (i.e., “reheat”), and then continue cooling.
  ```r
  mf %>% mif2(
      Nmif=100,rw.sd=rw.sd(Beta=0.01,mu_IR=0.01,eta=ivp(0.01))
    ) %>%
    mif2(
      Nmif=100,
      rw.sd=rw.sd(Beta=0.005,mu_IR=0.005,eta=ivp(0.005))
  ) -> mf
  ```

---