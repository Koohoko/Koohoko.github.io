---
title: "Paper digest: Simulation-based Inference for Partially Observed Markov Process Models with Spatial Coupling (Kidus Asfaw)"
date: 2023-07-04
permalink: /posts/2023-07-04/2023-07-04-spat-pomp
categories:
  - Paper digest
tags:
  - Infectious Disease Modelling
toc: true
last_modified_at: 2022-10-10
---

[This dissertation](https://deepblue.lib.umich.edu/handle/2027.42/169706) is the PhD thesis from Kidus Asfaw. Here I recorded some notes when I read it. There is also a preprint paper of this dissertation: [Partially observed Markov processes with spatial structure via the R package spatPomp](https://arxiv.org/abs/2101.01157).

Basically in this thesis, Kidus Asfaw introduced the SpatPomp model and its associated package. He also described several algorithms for calibrating the parameters e.g. GIRF, UBF, ABF, EnKF etc. in details in the paper. While I was studying this paper, I also found that there maybe some other useful (maybe better in some cases?) algorithms recently developed, e.g. [IBPF](https://arxiv.org/abs/2206.03837) (This was mentioned in the preprint paper but not in the thesis). There is also [slides](https://ionides.github.io/talks/mfo23.pdf) online about IBPF.

In the below section, I will take some notes which I think would be helpful to me from the thesis and paper.

## SpatPOMP models and their representation in spatPomp
### SpatPOMP models
- Suppose there are $U$ units labelled $1:U=\{1,2,...U\}$.
- Let $t_1<t_2<t_3<\cdots<t_N$ be a collection of time at which measurements are taken.
- We observe a measurement $y_{u,n}^{*}$ at time $t_n$ on unit $u$.
- We postulate a latent stochastic process $\bm{X}_{n} = (X_{1,n},...,X_{U,n})$ on unit $u$ at time $t_n$.
- The observation $y_{u,n}^{*}$ is modeled as a realization of an observable random variable $Y_{u,n}$.
- The process $\bm{X}_{0:N} = (\bm{X}_0, \bm{X}_1, ..., \bm{X}_N )$ is required to have the Markov property, i.e., $\bm{X}_{0:n−1}$ and $\bm{X}_{n+1:N}$ are conditionally independent given $\bm{X}_n$

### Implementation of SpatPOMP models
- **spatPomp** extends **pomp** by the addition of unit-level specification of the measurement model.
- There are five unit-level functionalities of class ‘spatPomp’ objects: `dunit_measure`, `runit_measure`, `eunit_measure`, `vunit_measure` and `munit_measure`.
- Data and observation times: The only mandatory arguments to the spatPomp() constructor are `data` (class `data.frame` object), `times`, `units` and `t0`. 
- Initial conditions: *initial value parameters* (IVPs) are components of the $\theta$ having the sole function of specifying $\bm{X}_0$. $\bm{X}_0$ is a draw from the initial distribution $f_{\bm{X}_0}(\bm{x}_0;\theta)$.
- Parameters involved in the tran- sition density or measurement density are called *regular parameters* (RPs)
- Covariates: In **spatPomp**, covariate processes can be supplied as a class `data.frame` object to the covar argument of the `spatPomp()` constructor function. This data.frame requires a column for time, spatial unit, and each of the covariates.
- Specifying model components using C snippets:
  - the names of the parameters and latent variables must be supplied to spatPomp using the `paramnames` and `unit_statenames` arguments.
  - unit-specific variable names can be supplied as needed via arguments to spatPomp_Csnippet. These can be used to specify the five `unit_measure` model components which specify properties of the spatially structured measurement model characteristic of a SpatPOMP.
  - For a `unit_measure` Csnippet, automatically defined variables also include the number of units, $\text{U}$, and an integer $\text{u}$ corresponding to a numeric unit from 0 to $\text{U}-1$.
  - A **spatPomp** Csnippet for `rprocess` will typically involve a computation looping through the units, which requires access to location data used to specify the interaction between units.
  - The location data can be made available to the Csnippet using the `globals` argument.
- Simulation is carried out by `simulate()` which requires specification of `rprocess` and `rmeasure`.

## Likelihood evaluation
### Four filters
In the spatiotemporal context, successful particle filtering requires state-of-the-art algorithms. Below, we introduce four such algorithms implemented in the **spatPomp** package: a guided intermediate resampling filter (GIRF) implemented as `girf`, an adapted bagged filter (ABF) implemented as `abf`, an ensemble Kalman filter (EnKF) implemented as `enkf`, and a block particle filter (BPF) implemented as `bpfilter`.

The filtering problem can be decomposed into two steps, **prediction** and **filtering**. For all the filters we consider here, the prediction step involves simulating from the latent process model. The algorithms differ primarily in their approaches to the filtering step, also known as the data assimilation step or the analysis step. 
- For PF, the filtering step is a weighted resampling from the prediction particles, and the instability of these weights in high dimensions is the fundamental scalability issue with the algorithm. 
- GIRF carries out this resampling at many intermediate timepoints with the goal of breaking an intractable resampling problem into a sequence of tractable ones. 
- EnKF estimates variances and covariances of the prediction simulations, and carries out an update rule that would be exact for a Gaussian system. 
- BPF carries out the resampling independently over a partition of the units, aiming for an inexact but numerically tractable approximation. 
- ABF combines together many high-variance filters using local weights to beat the curse of dimensionality.

### Considerations for choosing a filter
Of the four filters described above, only GIRF provides an unbiased estimate of the likeli- hood. However, GIRF has a relatively weak theoretical scaling support, beating the curse of dimensionality only in the impractical situation of an ideal guide function (Park and Ionides 2020). EnKF, ABF and BPF gain scalability by making different approximations that may or may not be appropriate for a given situation.

**EnKF** has low variance but is relatively sensitive to deviations from normality. **BPF** can break conservation laws satisfied by the latent process, such as a constraint on the total population in all units; **ABF** satisfies such constraints but has been found to have higher variance than BPF on some benchmark problems (Ionides et al. 2021). For the measles model built by `measles()`, **BPF and ABF** have been found to perform better than EnKF and GIRF (Ionides et al. 2021).

Through personal communication with Prof Iondies, I learned that the IBPF algorithm seems efficient and suitable for my study. On a new problem, it is advantageous to compare various algorithms to reveal unexpected limitations of the different approximations inherent in each algorithm.

## Likelihood maximization and inference for SpatPOMP models
We focus on iterated filtering methods (Ionides et al. 2015) which provide a relatively simple way to coerce filtering algorithms to carry out parameter inference, applicable to the general class of SpatPOMP models considered by spatPomp. 

The main idea of iterated filtering is to extend a POMP model to include dynamic parameter perturbations. Repeated filtering, with parameter perturbations of decreasing magnitude, approaches the maximum likelihood estimate.

Iterated block particle filter (IBPF): Any estimated parameter (whether shared or unit-specific) must be coded as a unit-specific parameter in order to apply this method. The spatiotemporal perturbations are used only as an optimization tool for model parameters which are fixed though time and space (for shared parameters) or just through time (for unit-specific parameters). The algorithm uses decreasing perturbation magnitudes so that the perturbed model approaches the fixed parameter model as the optimization proceeds. An example model compatible with `ibpf` is constructed by the `he10()` function. This builds a measles model similar to the `measles()` example discussed in Section 6, with the difference that the user can select which parameters are unit-specific.

## Data analysis tools on a toy model
We illustrate key capabilities of spatPomp using the `bm10` model for correlated Brownian motion.
### Computing the likelihood
```r
girf(bm10,Np=500,Nguide=50,Ninter=5,lookahead=1)
bpfilter(bm10, Np=2000, block_size=2)
enkf(bm10, Np=2000)
```
This generates objects of class `girfd_spatPomp`, `bpfiltered_spatPomp` and `enkfd_spatPomp` respectively. A plot method provides diagnostics, and the resulting log-likelihood estimate is extracted by `logLik`.

### Parameter inference
We start with a test of `igirf`, estimating the parameters $ρ$, $σ$ and $τ$ but not the initial value parameters. We use a computational intensity variable, `i`, to switch between algorithmic parameter settings. For debugging, testing and code development we use `i=1`. For a final version of the manuscript, we use `i=2`.
```r
start_params <- c(rho = 0.8, sigma = 0.4, tau = 0.2,
  X1_0 = 0, X2_0 = 0, X3_0 = 0, X4_0 = 0, X5_0 = 0,
  X6_0 = 0, X7_0 = 0, X8_0 = 0, X9_0 = 0, X10_0 = 0)
i <- 2
ig1 <- igirf(
  bm10,
  params=start_params,
  Ngirf=switch(i,2,50),
  Np=switch(i,10,1000),
  Ninter=switch(i,2,5),
  lookahead=1,
  Nguide=switch(i,5,50),
  rw.sd=rw.sd(rho=0.02,sigma=0.02,tau=0.02),
  cooling.type = "geometric",
  cooling.fraction.50=0.5
  )
```
`ig1` is an object of class `igirfd_spatpomp` which inherits from class `girfd_spatpomp`. A useful diagnostic of the parameter search is a plot of the change of the parameter estimates during the course of an `igirf()` run. Each iteration within an `igirf` run provides a parameter estimate and a likelihood evaluation at that estimate. The plot method for a class `igirfd_spatPomp` object shows the convergence record of parameter estimates and their likelihood evaluations.

### Monte Carlo profiles
Proper interpretation of a parameter estimate requires understanding its uncertainty. Here, we construct a profile likelihood 95% confidence interval for the coupling parameter, $ρ$, in the `bm10` model. This entails calculation of the maximized likelihood over all parameters excluding $ρ$, for a range of fixed values of $ρ$. We use Monte Carlo adjusted profile (MCAP) methodology to accommodate Monte Carlo error in maximization and likelihood evaluation (Ionides et al. 2017; Ning et al. 2021).

In practice, we carry out multiple searches for each value of $ρ$, with other parameters drawn at random from a specified hyperbox. We build this box on a transformed scale suitable for optimization, taking advantage of the `partrans` method. It is generally convenient to optimize non-negative parameters on a log scale and (0, 1) valued parameter on a logit scale. We set this up using the **pomp** function `profile_design`, taking advantage of the `partrans` method defined by the `partrans` argument to `spatPomp`.

```r
bm10 <- spatPomp(bm10,
  partrans = parameter_trans(log = c("sigma", "tau"), logit = c("rho")),
  paramnames = c("sigma","tau","rho") 
  )
```
This provides access to the partrans method which we use when constructing starting points for the search:

```r
theta_lo_trans <- partrans(bm10,coef(bm10),dir="toEst") - log(2)
theta_hi_trans <- partrans(bm10,coef(bm10),dir="toEst") + log(2)
profile_design(
  rho=seq(from=0.2,to=0.6,length=10),
  lower=partrans(bm10,theta_lo_trans,dir="fromEst"),
  upper=partrans(bm10,theta_hi_trans,dir="fromEst"),
  nprof=switch(i,2,10)
) -> pd
```
